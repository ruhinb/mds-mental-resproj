{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import json\n",
    "\n",
    "def tidy_text(raw_text):\n",
    "    return raw_text.strip().replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0', ' ')\n",
    "\n",
    "def parse_date_string(date_input):\n",
    "    date_input = str(date_input).strip()\n",
    "    today = datetime.today()\n",
    "\n",
    "    for fmt in (\"%d-%m-%Y %I:%M %p\", \"%d-%m-%Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(date_input, fmt).strftime(\"%Y-%m-%d\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    date_lower = date_input.lower()\n",
    "    rel_map = {\n",
    "        \"yesterday\": timedelta(days=1),\n",
    "        \"a week ago\": timedelta(weeks=1),\n",
    "        \"2 weeks ago\": timedelta(weeks=2),\n",
    "        \"3 weeks ago\": timedelta(weeks=3),\n",
    "        \"4 weeks ago\": timedelta(weeks=4),\n",
    "        \"a month ago\": timedelta(days=30)\n",
    "    }\n",
    "    if date_lower in rel_map:\n",
    "        return (today - rel_map[date_lower]).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    match = re.match(r\"(\\d+)\\s+(day|week|hour)s?\\s+ago\", date_lower)\n",
    "    if match:\n",
    "        amount = int(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        if unit == \"day\":\n",
    "            return (today - timedelta(days=amount)).strftime(\"%Y-%m-%d\")\n",
    "        elif unit == \"week\":\n",
    "            return (today - timedelta(weeks=amount)).strftime(\"%Y-%m-%d\")\n",
    "        elif unit == \"hour\":\n",
    "            return (today - timedelta(hours=amount)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    weekdays = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]\n",
    "    if date_lower in weekdays:\n",
    "        diff = (today.weekday() - weekdays.index(date_lower)) % 7\n",
    "        if diff == 0:\n",
    "            diff = 7\n",
    "        return (today - timedelta(days=diff)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_thread_content(browser, thread_url, max_replies=40):\n",
    "    replies = []\n",
    "    page_no = 1\n",
    "    main_post = None\n",
    "    reply_id = 1\n",
    "\n",
    "    while len(replies) < max_replies:\n",
    "        browser.get(thread_url)\n",
    "        time.sleep(3)\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        message_blocks = soup.find_all('div', class_='lia-panel-message')\n",
    "\n",
    "        if not message_blocks:\n",
    "            break\n",
    "\n",
    "        for idx, block in enumerate(message_blocks):\n",
    "            if page_no > 1 and idx == 0:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                text_tag = block.find('div', class_='lia-message-body-content')\n",
    "                comment_body = tidy_text(text_tag.get_text()) if text_tag else \"\"\n",
    "\n",
    "                author_tag = block.find('a', class_='lia-user-name-link')\n",
    "                author_name = author_tag.get_text(strip=True) if author_tag else \"Unknown\"\n",
    "\n",
    "                timestamp = \"Unknown\"\n",
    "                time_tag = block.find('span', class_='local-date')\n",
    "                if time_tag:\n",
    "                    raw_time = time_tag.text.replace(\"\\u200e\", \"\").strip()\n",
    "                    try:\n",
    "                        timestamp = datetime.strptime(raw_time, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
    "                    except Exception:\n",
    "                        timestamp = raw_time\n",
    "\n",
    "                if timestamp == \"Unknown\":\n",
    "                    time_tag = block.find('span', class_='local-friendly-date')\n",
    "                    if time_tag and time_tag.has_attr(\"title\"):\n",
    "                        raw_time = time_tag[\"title\"].replace(\"\\u200e\", \"\").strip()\n",
    "                        try:\n",
    "                            timestamp = datetime.strptime(raw_time, \"%d-%m-%Y %I:%M %p\").strftime(\"%Y-%m-%d\")\n",
    "                        except Exception:\n",
    "                            timestamp = raw_time\n",
    "\n",
    "                if page_no == 1 and idx == 0:\n",
    "                    main_post = comment_body\n",
    "                else:\n",
    "                    replies.append({\n",
    "                        \"comment_id\": f\"{reply_id}\",\n",
    "                        \"author\": author_name,\n",
    "                        \"timestamp\": timestamp,\n",
    "                        \"comment\": comment_body\n",
    "                    })\n",
    "                    reply_id += 1\n",
    "\n",
    "                if len(replies) >= max_replies:\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Comment parse failed: {e}\")\n",
    "                continue\n",
    "\n",
    "        next_btn = soup.find(\"a\", rel=\"next\")\n",
    "        if not next_btn:\n",
    "            break\n",
    "        href = next_btn.get(\"href\")\n",
    "        thread_url = href if href.startswith(\"http\") else \"https://forums.beyondblue.org.au\" + href\n",
    "        page_no += 1\n",
    "\n",
    "    return main_post, replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a60b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_forum_to_csv(categories, category_codes, page_limits):\n",
    "    chrome_opts = Options()\n",
    "    chrome_opts.add_argument(\"--disable-gpu\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    collected_posts = []\n",
    "    post_counter = 1\n",
    "\n",
    "    for idx, category in enumerate(categories):\n",
    "        code = category_codes[category]\n",
    "        for page in range(1, page_limits[idx] + 1):\n",
    "            url = f\"https://forums.beyondblue.org.au/t5/{category}/bd-p/{code}/page/{page}\"\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                time.sleep(3)\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                articles = soup.find('div', class_=\"custom-message-list all-discussions\").find_all(\"article\")\n",
    "\n",
    "                for article in articles:\n",
    "                    try:\n",
    "                        title_el = article.select_one(\"h3 > a[href*='/td-p/']\")\n",
    "                        title_text = title_el.text.strip()\n",
    "                        thread_link = \"https://forums.beyondblue.org.au\" + title_el[\"href\"]\n",
    "\n",
    "                        preview_el = article.select_one(\"p.body-text\")\n",
    "                        preview_text = preview_el.text.strip() if preview_el else \"\"\n",
    "\n",
    "                        author_el = article.select_one(\"div.custom-tile-author-info a\")\n",
    "                        author_name = author_el.text.strip() if author_el else \"Unknown\"\n",
    "\n",
    "                        date_el = article.select_one(\"div.custom-tile-date time\")\n",
    "                        if date_el:\n",
    "                            raw_date = date_el.get(\"datetime\") or date_el.text.strip()\n",
    "                            post_date = parse_date_string(raw_date)\n",
    "                        else:\n",
    "                            post_date = \"Unknown\"\n",
    "                        if post_date == \"Unknown\" or post_date < \"2019-01-01\":\n",
    "                            continue\n",
    "\n",
    "                        cat_el = article.select_one(\"div.custom-tile-category a\")\n",
    "                        category_name = cat_el.text.strip() if cat_el else category\n",
    "\n",
    "                        post_body, replies = fetch_thread_content(driver, thread_link, max_replies=40)\n",
    "\n",
    "                        collected_posts.append({\n",
    "                            \"post_id\": post_counter,\n",
    "                            \"title\": title_text,\n",
    "                            \"author\": author_name,\n",
    "                            \"date\": post_date,\n",
    "                            \"category\": category_name,\n",
    "                            \"preview\": preview_text,\n",
    "                            \"post_text\": post_body or \"\",\n",
    "                            \"num_comments\": len(replies),\n",
    "                            \"comments_combined\": json.dumps(replies),\n",
    "                            \"url\": thread_link\n",
    "                        })\n",
    "                        post_counter += 1\n",
    "                        print(f\"{thread_link} - comments: {len(replies)}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(\"Error in article block:\", e)\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                print(\"Failed to load page:\", url, e)\n",
    "                continue\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "\n",
    "    csv_path = \"data/beyondblue_updated.csv\"\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        fieldnames = [\n",
    "            \"post_id\", \"title\", \"author\", \"date\", \"category\",\n",
    "            \"preview\", \"post_text\", \"num_comments\", \"comments_combined\", \"url\"\n",
    "        ]\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in collected_posts:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"CSV saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec0520",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = ['anxiety', 'depression', 'ptsd-and-trauma', 'suicidal-thoughts-and-self-harm']\n",
    "category_code_map = {\n",
    "    'anxiety': 'c1-sc2-b1',\n",
    "    'depression': 'c1-sc2-b2',\n",
    "    'ptsd-and-trauma': 'c1-sc2-b3',\n",
    "    'suicidal-thoughts-and-self-harm': 'c1-sc2-b4'\n",
    "}\n",
    "page_count_list = [200, 200, 200, 200]\n",
    "\n",
    "scrape_forum_to_csv(category_list, category_code_map, page_count_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
