{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734d728f",
   "metadata": {},
   "source": [
    "## Data Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- SETUP REDDIT AUTH ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id='trvEAgsIJjIc4SpF1kASCg',\n",
    "    client_secret='QRgVLo1_3h1B02PINYv5uUcc1hK9aA',\n",
    "    user_agent='mental-health-resproj',\n",
    "    username='kohor_',\n",
    "    password='Sq5dS$*T7#8%gua92o@9'\n",
    ")\n",
    "\n",
    "# --- CONFIG ---\n",
    "subreddits = [\n",
    "    'depression',\n",
    "    'depression_help',\n",
    "    'anxiety',\n",
    "    'mentalhealth',\n",
    "    'SuicideWatch',\n",
    "    'DecidingToBeBetter',\n",
    "    'BipolarReddit',\n",
    "    'OCD',\n",
    "    'ADHD',\n",
    "    'therapy',\n",
    "    'StopSelfHarm',\n",
    "    'selfhelp',\n",
    "    'socialanxiety'\n",
    "]\n",
    "\n",
    "start_year = 2015\n",
    "start_timestamp = int(datetime(start_year, 1, 1).timestamp())\n",
    "\n",
    "post_data = []\n",
    "comment_data = []\n",
    "\n",
    "# --- SCRAPE ---\n",
    "for sub in subreddits:\n",
    "    print(f\"üîé Scraping r/{sub}...\")\n",
    "    try:\n",
    "        for post in reddit.subreddit(sub).new(limit=None):  # Get as many as allowed\n",
    "            if post.created_utc < start_timestamp:\n",
    "                continue\n",
    "\n",
    "            post_author = post.author.name if post.author else None\n",
    "\n",
    "            # Store post\n",
    "            post_data.append({\n",
    "                'subreddit': sub,\n",
    "                'id': post.id,\n",
    "                'title': post.title,\n",
    "                'text': post.selftext,\n",
    "                'author': post_author,\n",
    "                'score': post.score,\n",
    "                'num_comments': post.num_comments,\n",
    "                'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'url': post.url\n",
    "            })\n",
    "\n",
    "            # Load comments\n",
    "            post.comments.replace_more(limit=0)\n",
    "            for top_comment in post.comments:\n",
    "                comment_author = top_comment.author.name if top_comment.author else None\n",
    "                comment_entry = {\n",
    "                    'post_id': post.id,\n",
    "                    'comment_id': top_comment.id,\n",
    "                    'comment_author': comment_author,\n",
    "                    'comment_body': top_comment.body,\n",
    "                    'comment_score': top_comment.score,\n",
    "                    'comment_created': datetime.utcfromtimestamp(top_comment.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'author_reply': None,\n",
    "                    'author_reply_id': None\n",
    "                }\n",
    "\n",
    "                # Search for author reply to this comment\n",
    "                for reply in top_comment.replies:\n",
    "                    if reply.author and reply.author.name == post_author:\n",
    "                        comment_entry['author_reply'] = reply.body\n",
    "                        comment_entry['author_reply_id'] = reply.id\n",
    "                        break  # First author reply is enough\n",
    "\n",
    "                comment_data.append(comment_entry)\n",
    "\n",
    "            # Optional: be nice to Reddit API\n",
    "            time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error scraping r/{sub}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- SAVE ---\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Save posts\n",
    "df_posts = pd.DataFrame(post_data)\n",
    "df_posts.to_csv(\"data/reddit_posts_mentalhealth_2015_present.csv\", index=False)\n",
    "\n",
    "# Save comments + replies\n",
    "df_comments = pd.DataFrame(comment_data)\n",
    "df_comments.to_csv(\"data/reddit_comments_with_author_replies.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Scraped {len(df_posts)} posts and {len(df_comments)} comments with potential author replies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# --- SETUP REDDIT AUTH ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id='trvEAgsIJjIc4SpF1kASCg',\n",
    "    client_secret='QRgVLo1_3h1B02PINYv5uUcc1kK9aA',\n",
    "    user_agent='mental-health-resproj',\n",
    "    username='kohor_',\n",
    "    password='Sq5dS$*T7#8%gua92o@9'\n",
    ")\n",
    "\n",
    "# --- CONFIG ---\n",
    "subreddits = [\n",
    "    'depression',\n",
    "    'depression_help',\n",
    "    'anxiety',\n",
    "    'mentalhealth',\n",
    "    'SuicideWatch',\n",
    "    'DecidingToBeBetter',\n",
    "    'BipolarReddit',\n",
    "    'OCD',\n",
    "    'ADHD',\n",
    "    'therapy',\n",
    "    'StopSelfHarm',\n",
    "    'selfhelp',\n",
    "    'socialanxiety'\n",
    "]\n",
    "\n",
    "post_limit = 2000\n",
    "\n",
    "post_data = []\n",
    "comment_data = []\n",
    "\n",
    "# --- SCRAPE ---\n",
    "for sub in subreddits:\n",
    "    print(f\"üîé Scraping r/{sub} (up to {post_limit} posts)...\")\n",
    "    try:\n",
    "        for post in reddit.subreddit(sub).new(limit=post_limit):\n",
    "            post_author = post.author.name if post.author else None\n",
    "\n",
    "            # Store post info\n",
    "            post_data.append({\n",
    "                'subreddit': sub,\n",
    "                'post_id': post.id,\n",
    "                'title': post.title,\n",
    "                'text': post.selftext,\n",
    "                'author': post_author,\n",
    "                'score': post.score,\n",
    "                'num_comments': post.num_comments,\n",
    "                'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'url': post.url\n",
    "            })\n",
    "\n",
    "            # Load comments\n",
    "            post.comments.replace_more(limit=0)\n",
    "            for top_comment in post.comments:\n",
    "                comment_author = top_comment.author.name if top_comment.author else None\n",
    "                comment_entry = {\n",
    "                    'post_id': post.id,\n",
    "                    'comment_id': top_comment.id,\n",
    "                    'comment_author': comment_author,\n",
    "                    'comment_body': top_comment.body,\n",
    "                    'comment_score': top_comment.score,\n",
    "                    'comment_created': datetime.utcfromtimestamp(top_comment.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'author_reply': None,\n",
    "                    'author_reply_id': None\n",
    "                }\n",
    "\n",
    "                # Check if post author replied to this comment\n",
    "                for reply in top_comment.replies:\n",
    "                    if reply.author and reply.author.name == post_author:\n",
    "                        comment_entry['author_reply'] = reply.body\n",
    "                        comment_entry['author_reply_id'] = reply.id\n",
    "                        break  # only first author reply\n",
    "\n",
    "                comment_data.append(comment_entry)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error scraping r/{sub}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "df_posts = pd.DataFrame(post_data)\n",
    "df_posts.to_csv(\"data/reddit_data_posts.csv\", index=False)\n",
    "\n",
    "df_comments = pd.DataFrame(comment_data)\n",
    "df_comments.to_csv(\"data/reddit_data_comments_with_author_replies.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done! {len(df_posts)} posts and {len(df_comments)} comments (with author replies where available) saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- SETUP REDDIT AUTH ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id='trvEAgsIJjIc4SpF1kASCg',\n",
    "    client_secret='QRgVLo1_3h1B02PINYv5uUcc1kK9aA',\n",
    "    user_agent='mental-health-resproj',\n",
    "    username='kohor_',\n",
    "    password='Sq5dS$*T7#8%gua92o@9'\n",
    ")\n",
    "\n",
    "# --- CONFIG ---\n",
    "subreddits = [\n",
    "    'depression', 'depression_help', 'anxiety', 'mentalhealth',\n",
    "    'SuicideWatch', 'DecidingToBeBetter', 'BipolarReddit',\n",
    "    'OCD', 'ADHD', 'therapy', 'StopSelfHarm', 'selfhelp', 'socialanxiety'\n",
    "]\n",
    "\n",
    "target_limit = 2000  # total posts per subreddit\n",
    "chunk_size = 200     # posts per request\n",
    "sleep_secs = 2       # delay between chunks\n",
    "\n",
    "post_data = []\n",
    "comment_data = []\n",
    "\n",
    "for sub in subreddits:\n",
    "    print(f\"\\nüîé Scraping r/{sub} (target: {target_limit} posts)...\")\n",
    "    count = 0\n",
    "    try:\n",
    "        submissions = reddit.subreddit(sub).new(limit=None)\n",
    "        for post in submissions:\n",
    "            if count >= target_limit:\n",
    "                break\n",
    "\n",
    "            post_author = post.author.name if post.author else None\n",
    "            post_data.append({\n",
    "                'subreddit': sub,\n",
    "                'post_id': post.id,\n",
    "                'title': post.title,\n",
    "                'text': post.selftext,\n",
    "                'author': post_author,\n",
    "                'score': post.score,\n",
    "                'num_comments': post.num_comments,\n",
    "                'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'url': post.url\n",
    "            })\n",
    "\n",
    "            try:\n",
    "                post.comments.replace_more(limit=0)\n",
    "                for top_comment in post.comments:\n",
    "                    comment_author = top_comment.author.name if top_comment.author else None\n",
    "                    comment_entry = {\n",
    "                        'post_id': post.id,\n",
    "                        'comment_id': top_comment.id,\n",
    "                        'comment_author': comment_author,\n",
    "                        'comment_body': top_comment.body,\n",
    "                        'comment_score': top_comment.score,\n",
    "                        'comment_created': datetime.utcfromtimestamp(top_comment.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        'author_reply': None,\n",
    "                        'author_reply_id': None\n",
    "                    }\n",
    "\n",
    "                    for reply in top_comment.replies:\n",
    "                        if reply.author and reply.author.name == post_author:\n",
    "                            comment_entry['author_reply'] = reply.body\n",
    "                            comment_entry['author_reply_id'] = reply.id\n",
    "                            break\n",
    "\n",
    "                    comment_data.append(comment_entry)\n",
    "            except Exception as ce:\n",
    "                print(f\"‚ö†Ô∏è Error loading comments for post {post.id}: {ce}\")\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count % chunk_size == 0:\n",
    "                print(f\"  ...scraped {count} posts from r/{sub} so far\")\n",
    "                time.sleep(sleep_secs)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error scraping r/{sub}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- SAVE TO CSV ---\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df_posts = pd.DataFrame(post_data)\n",
    "df_posts.to_csv(\"data/reddit_data_posts.csv\", index=False)\n",
    "\n",
    "df_comments = pd.DataFrame(comment_data)\n",
    "df_comments.to_csv(\"data/reddit_data_comments_with_author_replies.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done! {len(df_posts)} posts and {len(df_comments)} comments saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- SETUP REDDIT AUTH ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id='trvEAgsIJjIc4SpF1kASCg',\n",
    "    client_secret='QRgVLo1_3h1B02PINYv5uUcc1hK9aA',\n",
    "    user_agent='mental-health-resproj',\n",
    "    username='kohor_',\n",
    "    password='Sq5dS$*T7#8%gua92o@9'\n",
    ")\n",
    "\n",
    "# --- CONFIG ---\n",
    "subreddits = [\n",
    "    'depression', 'depression_help', 'anxiety', 'mentalhealth',\n",
    "    'SuicideWatch', 'DecidingToBeBetter', 'BipolarReddit',\n",
    "    'OCD', 'ADHD', 'therapy', 'StopSelfHarm', 'selfhelp', 'socialanxiety'\n",
    "]\n",
    "\n",
    "start_year = 2015\n",
    "start_timestamp = int(datetime(start_year, 1, 1).timestamp())\n",
    "\n",
    "post_limit = 500  # sensible number per subreddit\n",
    "\n",
    "post_data = []\n",
    "comment_data = []\n",
    "\n",
    "# --- SCRAPE ---\n",
    "for sub in subreddits:\n",
    "    print(f\"üîé Scraping top posts from r/{sub}...\")\n",
    "    try:\n",
    "        for post in reddit.subreddit(sub).top(limit=post_limit):\n",
    "            if post.created_utc < start_timestamp:\n",
    "                continue  # skip old posts\n",
    "\n",
    "            post_author = post.author.name if post.author else None\n",
    "\n",
    "            # Save post\n",
    "            post_data.append({\n",
    "                'subreddit': sub,\n",
    "                'id': post.id,\n",
    "                'title': post.title,\n",
    "                'text': post.selftext,\n",
    "                'author': post_author,\n",
    "                'score': post.score,\n",
    "                'num_comments': post.num_comments,\n",
    "                'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'url': post.url\n",
    "            })\n",
    "\n",
    "            # Comments and author replies\n",
    "            try:\n",
    "                post.comments.replace_more(limit=0)\n",
    "                for top_comment in post.comments:\n",
    "                    comment_author = top_comment.author.name if top_comment.author else None\n",
    "                    comment_entry = {\n",
    "                        'post_id': post.id,\n",
    "                        'comment_id': top_comment.id,\n",
    "                        'comment_author': comment_author,\n",
    "                        'comment_body': top_comment.body,\n",
    "                        'comment_score': top_comment.score,\n",
    "                        'comment_created': datetime.utcfromtimestamp(top_comment.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        'author_reply': None,\n",
    "                        'author_reply_id': None\n",
    "                    }\n",
    "\n",
    "                    for reply in top_comment.replies:\n",
    "                        if reply.author and reply.author.name == post_author:\n",
    "                            comment_entry['author_reply'] = reply.body\n",
    "                            comment_entry['author_reply_id'] = reply.id\n",
    "                            break\n",
    "\n",
    "                    comment_data.append(comment_entry)\n",
    "            except Exception as ce:\n",
    "                print(f\"‚ö†Ô∏è Comment error in post {post.id}: {ce}\")\n",
    "\n",
    "            time.sleep(0.5)  # polite delay\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error scraping r/{sub}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- SAVE ---\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "df_posts = pd.DataFrame(post_data)\n",
    "df_posts.to_csv(\"data/reddit_posts_top500.csv\", index=False)\n",
    "\n",
    "df_comments = pd.DataFrame(comment_data)\n",
    "df_comments.to_csv(\"data/reddit_comments_top500.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Finished! {len(df_posts)} posts and {len(df_comments)} comments saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fcb0035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Scraping top 2000 posts from r/depression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/36rrr53s1w388ms7208drrcm0000gn/T/ipykernel_22324/2496719970.py:38: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Scraping top 2000 posts from r/depression_help...\n",
      "üîé Scraping top 2000 posts from r/anxiety...\n",
      "üîé Scraping top 2000 posts from r/mentalhealth...\n",
      "üîé Scraping top 2000 posts from r/SuicideWatch...\n",
      "üîé Scraping top 2000 posts from r/DecidingToBeBetter...\n",
      "üîé Scraping top 2000 posts from r/BipolarReddit...\n",
      "üîé Scraping top 2000 posts from r/OCD...\n",
      "üîé Scraping top 2000 posts from r/ADHD...\n",
      "üîé Scraping top 2000 posts from r/therapy...\n",
      "üîé Scraping top 2000 posts from r/selfhelp...\n",
      "üîé Scraping top 2000 posts from r/socialanxiety...\n",
      "\n",
      "‚úÖ Done! Scraped 11933 posts. Saved to: data/reddit_top2000_posts_per_subreddit.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# --- SETUP REDDIT AUTH ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id='trvEAgsIJjIc4SpF1kASCg',\n",
    "    client_secret='QRgVLo1_3h1B02PINYv5uUcc1hK9aA',\n",
    "    user_agent='mental-health-resproj',\n",
    "    username='kohor_',\n",
    "    password='Sq5dS$*T7#8%gua92o@9'\n",
    ")\n",
    "\n",
    "# --- CONFIG ---\n",
    "subreddits = [\n",
    "    'depression', 'depression_help', 'anxiety', 'mentalhealth',\n",
    "    'SuicideWatch', 'DecidingToBeBetter', 'BipolarReddit',\n",
    "    'OCD', 'ADHD', 'therapy', 'selfhelp', 'socialanxiety'\n",
    "]\n",
    "\n",
    "post_limit = 2000  # number of top posts per subreddit\n",
    "post_data = []\n",
    "\n",
    "# --- SCRAPE POSTS ONLY ---\n",
    "for sub in subreddits:\n",
    "    print(f\"üîé Scraping top {post_limit} posts from r/{sub}...\")\n",
    "    try:\n",
    "        for post in reddit.subreddit(sub).top(limit=post_limit):\n",
    "            post_data.append({\n",
    "                'subreddit': sub,\n",
    "                'id': post.id,\n",
    "                'title': post.title,\n",
    "                'text': post.selftext,\n",
    "                'author': post.author.name if post.author else None,\n",
    "                'score': post.score,\n",
    "                'num_comments': post.num_comments,\n",
    "                'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'url': post.url\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error scraping r/{sub}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- SAVE ---\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df = pd.DataFrame(post_data)\n",
    "df.to_csv(\"data/reddit_top2000_posts_per_subreddit.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done! Scraped {len(df)} posts. Saved to: data/reddit_top2000_posts_per_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3e6bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Scraping top posts from r/depression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/36rrr53s1w388ms7208drrcm0000gn/T/ipykernel_22324/1317595664.py:58: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collected 533 posts from r/depression\n",
      "üîé Scraping top posts from r/depression_help...\n",
      "‚úÖ Collected 563 posts from r/depression_help\n",
      "üîé Scraping top posts from r/anxiety...\n",
      "‚úÖ Collected 686 posts from r/anxiety\n",
      "üîé Scraping top posts from r/mentalhealth...\n",
      "‚úÖ Collected 565 posts from r/mentalhealth\n",
      "üîé Scraping top posts from r/SuicideWatch...\n",
      "‚úÖ Collected 439 posts from r/SuicideWatch\n",
      "üîé Scraping top posts from r/DecidingToBeBetter...\n",
      "‚úÖ Collected 518 posts from r/DecidingToBeBetter\n",
      "üîé Scraping top posts from r/BipolarReddit...\n",
      "‚úÖ Collected 479 posts from r/BipolarReddit\n",
      "üîé Scraping top posts from r/OCD...\n",
      "‚úÖ Collected 131 posts from r/OCD\n",
      "üîé Scraping top posts from r/ADHD...\n",
      "‚úÖ Collected 487 posts from r/ADHD\n",
      "üîé Scraping top posts from r/therapy...\n",
      "‚úÖ Collected 708 posts from r/therapy\n",
      "üîé Scraping top posts from r/selfhelp...\n",
      "‚úÖ Collected 584 posts from r/selfhelp\n",
      "üîé Scraping top posts from r/socialanxiety...\n",
      "‚úÖ Collected 92 posts from r/socialanxiety\n",
      "\n",
      "‚úÖ Total scraped: 5785 posts. Saved to data/reddit_top2000_filtered_mentalhealth.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# --- SETUP REDDIT AUTH ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id='trvEAgsIJjIc4SpF1kASCg',\n",
    "    client_secret='QRgVLo1_3h1B02PINYv5uUcc1hK9aA',\n",
    "    user_agent='mental-health-resproj',\n",
    "    username='kohor_',\n",
    "    password='Sq5dS$*T7#8%gua92o@9'\n",
    ")\n",
    "\n",
    "# --- CONFIG ---\n",
    "subreddits = [\n",
    "    'depression', 'depression_help', 'anxiety', 'mentalhealth',\n",
    "    'SuicideWatch', 'DecidingToBeBetter', 'BipolarReddit',\n",
    "    'OCD', 'ADHD', 'therapy', 'selfhelp', 'socialanxiety'\n",
    "]\n",
    "\n",
    "post_limit_per_subreddit = 2000\n",
    "pull_limit = 3000  # how many to initially pull from Reddit API\n",
    "\n",
    "mental_keywords = [\n",
    "    'depression', 'anxiety', 'suicidal', 'panic', 'breakdown', 'stress',\n",
    "    'burnout', 'therapy', 'mental health', 'struggling', 'psychologist',\n",
    "    'overwhelmed', 'help', 'support', 'hopeless', 'medication', 'insomnia'\n",
    "]\n",
    "\n",
    "def contains_keywords(text, keywords):\n",
    "    if not text:\n",
    "        return False\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword in text_lower for keyword in keywords)\n",
    "\n",
    "post_data = []\n",
    "\n",
    "# --- SCRAPE ---\n",
    "for sub in subreddits:\n",
    "    print(f\"üîé Scraping top posts from r/{sub}...\")\n",
    "    count = 0\n",
    "    try:\n",
    "        for post in reddit.subreddit(sub).top(limit=pull_limit):\n",
    "            if count >= post_limit_per_subreddit:\n",
    "                break\n",
    "            \n",
    "            combined_text = f\"{post.title or ''} {post.selftext or ''}\"\n",
    "            if contains_keywords(combined_text, mental_keywords):\n",
    "                post_data.append({\n",
    "                    'subreddit': sub,\n",
    "                    'id': post.id,\n",
    "                    'title': post.title,\n",
    "                    'text': post.selftext,\n",
    "                    'author': post.author.name if post.author else None,\n",
    "                    'score': post.score,\n",
    "                    'num_comments': post.num_comments,\n",
    "                    'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'url': post.url\n",
    "                })\n",
    "                count += 1\n",
    "\n",
    "        print(f\"‚úÖ Collected {count} posts from r/{sub}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error scraping r/{sub}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- SAVE ---\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df = pd.DataFrame(post_data)\n",
    "df.to_csv(\"data/reddit_top2000_filtered_mentalhealth.csv\", index=False)\n",
    "print(f\"\\n‚úÖ Total scraped: {len(df)} posts. Saved to data/reddit_top2000_filtered_mentalhealth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c99a36e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Scraping top posts from r/depression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/36rrr53s1w388ms7208drrcm0000gn/T/ipykernel_22324/3429802409.py:58: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collected 533 posts from r/depression\n",
      "üîé Scraping top posts from r/depression_help...\n",
      "‚úÖ Collected 563 posts from r/depression_help\n",
      "üîé Scraping top posts from r/anxiety...\n",
      "‚úÖ Collected 686 posts from r/anxiety\n",
      "üîé Scraping top posts from r/mentalhealth...\n",
      "‚úÖ Collected 565 posts from r/mentalhealth\n",
      "üîé Scraping top posts from r/SuicideWatch...\n",
      "‚úÖ Collected 439 posts from r/SuicideWatch\n",
      "üîé Scraping top posts from r/DecidingToBeBetter...\n",
      "‚úÖ Collected 518 posts from r/DecidingToBeBetter\n",
      "üîé Scraping top posts from r/BipolarReddit...\n",
      "‚úÖ Collected 479 posts from r/BipolarReddit\n",
      "üîé Scraping top posts from r/OCD...\n",
      "‚úÖ Collected 131 posts from r/OCD\n",
      "üîé Scraping top posts from r/ADHD...\n",
      "‚úÖ Collected 487 posts from r/ADHD\n",
      "üîé Scraping top posts from r/therapy...\n",
      "‚úÖ Collected 708 posts from r/therapy\n",
      "üîé Scraping top posts from r/selfhelp...\n",
      "‚úÖ Collected 584 posts from r/selfhelp\n",
      "üîé Scraping top posts from r/socialanxiety...\n",
      "‚úÖ Collected 92 posts from r/socialanxiety\n",
      "\n",
      "‚úÖ Total scraped: 5785 posts. Saved to data/reddit_top2000_filtered_mentalhealth.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# --- SETUP REDDIT AUTH ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id='trvEAgsIJjIc4SpF1kASCg',\n",
    "    client_secret='QRgVLo1_3h1B02PINYv5uUcc1hK9aA',\n",
    "    user_agent='mental-health-resproj',\n",
    "    username='kohor_',\n",
    "    password='Sq5dS$*T7#8%gua92o@9'\n",
    ")\n",
    "\n",
    "# --- CONFIG ---\n",
    "subreddits = [\n",
    "    'depression', 'depression_help', 'anxiety', 'mentalhealth',\n",
    "    'SuicideWatch', 'DecidingToBeBetter', 'BipolarReddit',\n",
    "    'OCD', 'ADHD', 'therapy', 'selfhelp', 'socialanxiety'\n",
    "]\n",
    "\n",
    "post_limit_per_subreddit = 8000\n",
    "pull_limit = 10000  # how many to initially pull from Reddit API\n",
    "\n",
    "mental_keywords = [\n",
    "    'depression', 'anxiety', 'suicidal', 'panic', 'breakdown', 'stress',\n",
    "    'burnout', 'therapy', 'mental health', 'struggling', 'psychologist',\n",
    "    'overwhelmed', 'help', 'support', 'hopeless', 'medication', 'insomnia'\n",
    "]\n",
    "\n",
    "def contains_keywords(text, keywords):\n",
    "    if not text:\n",
    "        return False\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword in text_lower for keyword in keywords)\n",
    "\n",
    "post_data = []\n",
    "\n",
    "# --- SCRAPE ---\n",
    "for sub in subreddits:\n",
    "    print(f\"üîé Scraping top posts from r/{sub}...\")\n",
    "    count = 0\n",
    "    try:\n",
    "        for post in reddit.subreddit(sub).top(limit=pull_limit):\n",
    "            if count >= post_limit_per_subreddit:\n",
    "                break\n",
    "            \n",
    "            combined_text = f\"{post.title or ''} {post.selftext or ''}\"\n",
    "            if contains_keywords(combined_text, mental_keywords):\n",
    "                post_data.append({\n",
    "                    'subreddit': sub,\n",
    "                    'id': post.id,\n",
    "                    'title': post.title,\n",
    "                    'text': post.selftext,\n",
    "                    'author': post.author.name if post.author else None,\n",
    "                    'score': post.score,\n",
    "                    'num_comments': post.num_comments,\n",
    "                    'created_utc': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'url': post.url\n",
    "                })\n",
    "                count += 1\n",
    "\n",
    "        print(f\"‚úÖ Collected {count} posts from r/{sub}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error scraping r/{sub}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- SAVE ---\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df = pd.DataFrame(post_data)\n",
    "df.to_csv(\"data/reddit_top2000_filtered_mentalhealth.csv\", index=False)\n",
    "print(f\"\\n‚úÖ Total scraped: {len(df)} posts. Saved to data/reddit_top2000_filtered_mentalhealth.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
