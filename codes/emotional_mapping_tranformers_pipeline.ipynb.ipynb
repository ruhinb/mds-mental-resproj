{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Load your flattened dataset\n",
    "import pandas as pd\n",
    "\n",
    "df_flat = pd.read_csv(\"data/beyondblue_data_flattened.csv\")\n",
    "df_flat['text'] = df_flat['text'].astype(str).fillna(\"\")\n",
    "df_flat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a400e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) force Transformers to use PyTorch only (avoid TF/Keras path)\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d27a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.3.1\n",
      "transformers: 4.41.2\n",
      "CUDA available? False\n"
     ]
    }
   ],
   "source": [
    "# 3) verify versions and device\n",
    "import torch, transformers\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "DEVICE = 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea372a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# sentiment pipeline (no change needed, just ignore pooler warning)\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipe = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    framework=\"pt\",\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# emotion pipeline (updated for new API)\n",
    "emotion_pipe = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    framework=\"pt\",\n",
    "    top_k=None,    # replaces return_all_scores=True\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7d6106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: [{'label': 'negative', 'score': 0.862205445766449}, {'label': 'positive', 'score': 0.9792223572731018}]\n",
      "emotion dist (first): [{'label': 'sadness', 'score': 0.8041720986366272}, {'label': 'neutral', 'score': 0.07814598083496094}, {'label': 'fear', 'score': 0.050828780978918076}, {'label': 'anger', 'score': 0.047112248837947845}, {'label': 'disgust', 'score': 0.008193270303308964}, {'label': 'surprise', 'score': 0.007894475944340229}, {'label': 'joy', 'score': 0.0036531074438244104}]\n"
     ]
    }
   ],
   "source": [
    "# 5) quick smoke test\n",
    "texts = [\n",
    "    \"I can't sleep and my mind won't stop racing.\",\n",
    "    \"Thank you for being there â€” I feel hopeful.\"\n",
    "]\n",
    "print(\"sentiment:\", sentiment_pipe(texts))\n",
    "print(\"emotion dist (first):\", emotion_pipe(texts)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb70e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
